{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from cnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/dataset/sign_mnist_train.csv\")\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (27455, 784)\n",
      "y_train shape:  (27455,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "print(\"x_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (24709, 784)\n",
      "x_val shape (2746, 784)\n",
      "y_train shape (24709,)\n",
      "y_val shape (2746,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_val shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_val shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (24709, 28, 28, 1)\n",
      "x_val shape:  (2746, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_val = X_val.values.reshape(-1,28,28,1)\n",
    "print(\"x_train shape: \",X_train.shape)\n",
    "print(\"x_val shape: \",X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (24709, 25)\n",
      "y_val shape:  (2746, 25)\n"
     ]
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 25)\n",
    "Y_val = to_categorical(Y_val, num_classes = 25)\n",
    "print(\"y_train shape: \",Y_train.shape)\n",
    "print(\"y_val shape: \",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32,shape=[None, n_H0, n_W0, n_C0], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32,shape=[None, n_y], name = \"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 1, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "                        W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = tf.Variable(tf.glorot_uniform_initializer()((4, 4, 1, 8)))\n",
    "    W2 = tf.Variable(tf.glorot_uniform_initializer()((2, 2, 8, 16)))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Note that for simplicity and grading purposes, we'll hard-code some values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    # FLATTEN\n",
    "    F = tf.compat.v1.layers.flatten(P2)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 25 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.compat.v1.layers.dense(F, 25,activation=None)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 25)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels = Y,logits = Z3))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 200, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 28, 28, 1)\n",
    "    Y_train -- test set, of shape (None, n_y = 25)\n",
    "    X_test -- training set, of shape (None, 28, 28, 1)\n",
    "    Y_test -- test set, of shape (None, n_y = 25)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 200 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \"\"\"\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost.\n",
    "                # The feedict should contain a minibatch for (X,Y).\n",
    "                \"\"\"\n",
    "                _ , temp_cost = sess.run(fetches=[optimizer, cost],feed_dict={X: minibatch_X,Y: minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Val Accuracy:\", test_accuracy)\n",
    "        # Save the variables to disk\n",
    "        save_path = tf.train.Saver().save(sess, \"/tmp/model.ckpt\")\n",
    "        print (f\"Variables saved in path: {save_path}\")\n",
    "        # Save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-9-66b42bb97118>:36: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a30bffe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a30bffe50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a30bffe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1a30bffe50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-9-66b42bb97118>:39: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1a30bffe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1a30bffe50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1a30bffe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1a30bffe50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Cost after epoch 0: 2.319492\n",
      "Cost after epoch 5: 0.854238\n",
      "Cost after epoch 10: 0.660266\n",
      "Cost after epoch 15: 0.543982\n",
      "Cost after epoch 20: 0.471656\n",
      "Cost after epoch 25: 0.428179\n",
      "Cost after epoch 30: 0.398600\n",
      "Cost after epoch 35: 0.375422\n",
      "Cost after epoch 40: 0.362920\n",
      "Cost after epoch 45: 0.353194\n",
      "Cost after epoch 50: 0.345035\n",
      "Cost after epoch 55: 0.329205\n",
      "Cost after epoch 60: 0.318409\n",
      "Cost after epoch 65: 0.314320\n",
      "Cost after epoch 70: 0.305447\n",
      "Cost after epoch 75: 0.298267\n",
      "Cost after epoch 80: 0.296514\n",
      "Cost after epoch 85: 0.288466\n",
      "Cost after epoch 90: 0.282164\n",
      "Cost after epoch 95: 0.282209\n",
      "Cost after epoch 100: 0.279826\n",
      "Cost after epoch 105: 0.281091\n",
      "Cost after epoch 110: 0.274188\n",
      "Cost after epoch 115: 0.275421\n",
      "Cost after epoch 120: 0.272001\n",
      "Cost after epoch 125: 0.261998\n",
      "Cost after epoch 130: 0.268887\n",
      "Cost after epoch 135: 0.261573\n",
      "Cost after epoch 140: 0.254128\n",
      "Cost after epoch 145: 0.257857\n",
      "Cost after epoch 150: 0.253236\n",
      "Cost after epoch 155: 0.248874\n",
      "Cost after epoch 160: 0.255899\n",
      "Cost after epoch 165: 0.260339\n",
      "Cost after epoch 170: 0.249092\n",
      "Cost after epoch 175: 0.258926\n",
      "Cost after epoch 180: 0.273480\n",
      "Cost after epoch 185: 0.247438\n",
      "Cost after epoch 190: 0.241983\n",
      "Cost after epoch 195: 0.235623\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.9210409\n",
      "Val Accuracy: 0.91551346\n",
      "Variables saved in path: /tmp/model.ckpt\n",
      "Parameters have been trained!\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test1 = pd.read_csv(\"/Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/dataset/sign_mnist_test.csv\")\n",
    "X_test1 = test1.drop(labels = [\"label\"],axis = 1)\n",
    "img = X_test1.iloc[5].values\n",
    "img = img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(test1.iloc[5,0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/cnn_utils.py:93: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/cnn_utils.py:99: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/cnn_utils.py:76: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x105f8a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x105f8a250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x105f8a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x105f8a250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x105f8a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x105f8a250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x105f8a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x105f8a250>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/cnn_utils.py:104: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/martinyeh/Desktop/DeepLearning_WU/myproject/CNN/cnn_utils.py:105: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Your algorithm predicts: y = 21\n"
     ]
    }
   ],
   "source": [
    "X_test1=X_test1/ 255.0\n",
    "my_image_prediction = predict(X_test1.iloc[5].values.reshape((-1,28,28,1)), parameters)\n",
    "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
